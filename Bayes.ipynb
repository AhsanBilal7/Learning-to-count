{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "# from future.utils import iteritems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths to your dataset directory\n",
    "dataset_dir = './shapes_dataset_HR'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Define the ratio of data to be used for training (0.8 = 80% training, 20% testing)\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each class folder in the dataset directory\n",
    "for class_folder in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_folder)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(class_path):\n",
    "        # List all images in the class folder\n",
    "        images = [f for f in os.listdir(class_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "        \n",
    "        # Shuffle the images randomly\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        # Calculate the number of images for training\n",
    "        num_train_images = int(len(images) * train_ratio)\n",
    "        \n",
    "        # Split the images into train and test sets\n",
    "        train_images = images[:num_train_images]\n",
    "        test_images = images[num_train_images:]\n",
    "        \n",
    "        # Move train images to the train directory\n",
    "        for image in train_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dest = os.path.join(train_dir, class_folder, image)\n",
    "            os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "            shutil.copy(src, dest)\n",
    "        \n",
    "        # Move test images to the test directory\n",
    "        for image in test_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dest = os.path.join(test_dir, class_folder, image)\n",
    "            os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "            shutil.copy(src, dest)\n",
    "\n",
    "print(\"Dataset successfully split into train and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (9625, 64, 64)\n",
      "Train labels shape: (9625,)\n",
      "Test images shape: (3627, 64, 64)\n",
      "Test labels shape: (3627,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define paths to your dataset directory\n",
    "dataset_dir = './shapes_dataset_HR'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "\n",
    "# Define the ratio of data to be used for training (0.8 = 80% training, 20% testing)\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "train_images = {}\n",
    "test_images = {}\n",
    "\n",
    "# Loop through each class folder in the dataset directory\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_folder in os.listdir(folder):\n",
    "        class_path = os.path.join(folder, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            for filename in os.listdir(class_path):\n",
    "                img = cv2.imread(os.path.join(class_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (64,64))\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(int(class_folder))  # Assuming class folder names are the labels\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load train images and labels into memory\n",
    "train_images, train_labels = load_images_and_labels(train_dir)\n",
    "\n",
    "# Load test images and labels into memory\n",
    "test_images, test_labels = load_images_and_labels(test_dir)\n",
    "\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test images shape:\", test_images.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain , Ytrain) , (Xtest , Ytest) = (train_images,  train_labels) , (test_images,test_labels)\n",
    "Xtrain = Xtrain.reshape(Xtrain.shape[0], -1)\n",
    "Xtest = Xtest.reshape(Xtest.shape[0], -1)\n",
    "Xtrain, Xtest = Xtrain/255.0 , Xtest/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Bayes(object):\n",
    "    def fit(self, x, y, smoothing = 1e-2):\n",
    "        n, d = x.shape     # n = number of samples, d = number of features\n",
    "        self.gaussians = dict()\n",
    "        self.priors = dict()\n",
    "        labels = set(y)     # Unique number of labels \n",
    "        for c in labels:\n",
    "            current_x = x[y == c]\n",
    "            self.gaussians[c] = {\n",
    "                'mean': current_x.mean(axis = 0),\n",
    "                'cov': np.cov(current_x.T) + np.eye(d) * smoothing     # Covariance matrix np.eye is the identity matrix # Smoothing so that if any singular matrix is there then it will not be singular\n",
    "            }\n",
    "            self.priors[c] = float(len(y[y == c])) / len(y)\n",
    "\n",
    "    def score(self, x, y):\n",
    "        p = self.predict(x)\n",
    "        return np.mean(p == y)\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump({'gaussians': self.gaussians, 'priors': self.priors}, file)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "            self.gaussians = model['gaussians']\n",
    "            self.priors = model['priors']\n",
    "            \n",
    "            \n",
    "    def predict(self, x):\n",
    "        n, d = x.shape\n",
    "        k = len(self.gaussians)     # Number of classes\n",
    "        log_p = np.zeros((n, k))\n",
    "        # for c, g in iteritems(self.gaussians):\n",
    "        for c, g in self.gaussians.items():\n",
    "            mean, cov = g['mean'], g['cov']\n",
    "            cov += np.eye(d) * 1e-6\n",
    "            cov_inv = np.linalg.inv(cov)\n",
    "            cov_det = np.linalg.det(cov)\n",
    "            log_prior =  np.log(self.priors[c])\n",
    "            for i in range(n):\n",
    "                t = x[i]\n",
    "                diff = t - mean\n",
    "                log_exponent = -0.5 * diff.dot(cov_inv).dot(diff)\n",
    "                log_likelihood = log_exponent  - 0.5 *d * np.log(2*np.pi) - 0.5 * np.log(np.abs(cov_det) + 1e-6) \n",
    "                log_p[i,c] = log_likelihood + log_prior\n",
    "        return np.argmax(log_p, axis = 1)\n",
    "        #     p[:, c] = mvn.logpdf(x, mean = mean, cov = cov) + np.log(self.priors[c])     # logpdf is the log of the probability density function\n",
    "        # return np.argmax(p, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9727792207792207\n",
      "Test Accuracy:  0.8957816377171216\n"
     ]
    }
   ],
   "source": [
    "model = Bayes()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(\"Training Accuracy: \", model.score(Xtrain, Ytrain))\n",
    "print(\"Test Accuracy: \", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_model('bayes_model_HR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
